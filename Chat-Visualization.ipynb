{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAryg3MEOCv7"
      },
      "source": [
        "# Analyzing a Telegram Group Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSdTAGFDwB2P",
        "outputId": "19245845-6b00-45ac-9d07-87428325b923"
      },
      "outputs": [],
      "source": [
        "# # Checking what version we have\n",
        "\n",
        "# import sys\n",
        "# import platform\n",
        "# print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVwg_DzSORqi",
        "outputId": "a512baea-0df3-4e7d-f166-aa088a957744"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if a GPU is available\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    print('GPU is NOT available')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTOQa-IAOCv9"
      },
      "outputs": [],
      "source": [
        "# !pip install germansentiment\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns  # Import seaborn for easy color palettes\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G58Vs_sDOCv-"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "On the desktop version of Telegram select the caht you want to analyze.\n",
        "\n",
        "Go to to right corner and select the drop down ... menu and then \"export caht history\"\n",
        "\n",
        "---------------\n",
        "\n",
        "For this Notebook, we will only look at text messages, so selecting different is optional.\n",
        "\n",
        "Click on format and select \"Machine-readable JSON\"\n",
        "\n",
        "---------------\n",
        "\n",
        "Then determine the path and begin the export.\n",
        "\n",
        "Once complete the messages will be stored in a ChatExport_YYYY_MM_DD folder in a result.json file.\n",
        "\n",
        "From here onwards we will work with this file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahoUyREXOCv-"
      },
      "source": [
        "## Data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYzNcLqwOCv_"
      },
      "outputs": [],
      "source": [
        "json_path = \"./result.json\"\n",
        "\n",
        "with open('./result.json', 'r', encoding=\"utf8\") as f:\n",
        "    data = json.load(f)\n",
        "df = pd.DataFrame(data[\"messages\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoRa2WgNOCwA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The following code loops through this dictionary to extract the text elements.\n",
        "def get_message_text_from_json(data):\n",
        "    '''\n",
        "    For this applied case, the input should be data[\"message\"].\n",
        "    Hence the part of the json data which contains message information.\n",
        "    If a person is being referenced, the text is stored as another dictionary.\n",
        "    The function then goes through all lines extract the message text from all types of messages.\n",
        "    '''\n",
        "    data_message_text = []\n",
        "    for i in data:\n",
        "        try:\n",
        "            i[\"text\"][0][\"text\"]\n",
        "        except TypeError:\n",
        "            message_text = i[\"text\"]\n",
        "        except IndexError:\n",
        "            message_text = i[\"text\"]\n",
        "        else:\n",
        "            odd_case = i[\"text\"]\n",
        "            odd_case_text = \"\"\n",
        "            for j in odd_case:\n",
        "                try:\n",
        "                    j[\"text\"]\n",
        "                except TypeError:\n",
        "                    odd_case_text += j\n",
        "                else:\n",
        "                    odd_case_text += j[\"text\"]\n",
        "            message_text = odd_case_text\n",
        "        data_message_text.append(message_text)\n",
        "    return data_message_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG7kzmggOCwA",
        "outputId": "e3f3488a-bff2-424a-aaaa-0899b30093f2"
      },
      "outputs": [],
      "source": [
        "# creating another column with the message text cleaned and concatenated\n",
        "df[\"text_cleaned\"] = get_message_text_from_json(data[\"messages\"])\n",
        "\n",
        "#checking if the lines are still alligned\n",
        "print(df[\"text_cleaned\"])\n",
        "print(\"\")\n",
        "print(df[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi2ZYuYOOCwB",
        "outputId": "78d482d1-e9d3-45ee-b526-ab806e2de205"
      },
      "outputs": [],
      "source": [
        "# shortening the names to only first and last name\n",
        "\n",
        "# Function to shorten names to the first three words\n",
        "def shorten_name(name):\n",
        "    if isinstance(name, str):\n",
        "        words = name.split()[:2]\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "\n",
        "# Apply the function to the 'from' column\n",
        "df['from'] = df['from'].apply(shorten_name)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df[\"from\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI861HzQOCwC",
        "outputId": "d2407853-09d6-420a-aa4d-18e994fd64fc"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "-8OBVTsPOCwC",
        "outputId": "40a992f7-484b-4da6-bfa5-596972e607d2"
      },
      "outputs": [],
      "source": [
        "name_counts = df['from'].value_counts()\n",
        "\n",
        "# Plot the bar plot\n",
        "name_counts.plot(kind='bar', figsize=(14, 6), color=\"pink\")\n",
        "plt.title('Number of Messages for Each Name')\n",
        "plt.xlabel('Name')\n",
        "plt.ylabel('Message Count')\n",
        "plt.grid(axis='y', linestyle='--', linewidth=1, color='lightgrey')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "aebYfT8jOCwE",
        "outputId": "79e1189e-9f75-424b-a810-95467f67e98e"
      },
      "outputs": [],
      "source": [
        "# Convert 'date' to datetime format\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Sort DataFrame by the first date in ascending order\n",
        "sorted_names = df.groupby('from')['date'].min().sort_values().index\n",
        "df['from'] = pd.Categorical(df['from'], categories=sorted_names, ordered=True)\n",
        "df.sort_values(['from', 'date'], inplace=True)\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot horizontal lines for each name, indicating first and last occurrences\n",
        "for i, (name, group) in enumerate(df.groupby('from')):\n",
        "    first_date = group['date'].iloc[0]\n",
        "    last_date = group['date'].iloc[-1]\n",
        "    color = sns.color_palette(\"husl\", n_colors=len(df['from'].unique()))[i]  # Use seaborn color palette\n",
        "    ax.plot([name, name], [first_date, last_date], marker='o', color=color)\n",
        "\n",
        "# Set axis labels and title\n",
        "ax.set_xlabel('Name')\n",
        "ax.set_ylabel('Timeline')\n",
        "ax.set_title('Timeline of First and Last Occurrences for Each Name')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add very light x gridlines in between the names\n",
        "ax.grid(axis=\"x\", linestyle='--', linewidth=1, color='lightgrey')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "SDDyabkAOCwF",
        "outputId": "d13f1e51-5c73-4364-f0df-f45034761367"
      },
      "outputs": [],
      "source": [
        "subset_cols = [\"from\", \"date\"]\n",
        "subset_df = df[subset_cols]\n",
        "subset_df['hour'] = subset_df['date'].dt.hour\n",
        "hour_counts = subset_df.value_counts(\"hour\")\n",
        "hour_counts = pd.DataFrame(hour_counts)\n",
        "hour_counts = hour_counts.reset_index()\n",
        "hour_counts= hour_counts.sort_values(by=\"hour\")\n",
        "try:\n",
        "  hour_counts[\"count\"]\n",
        "except KeyError:\n",
        "  hour_counts.rename(columns={0: \"count\"}, inplace=True)\n",
        "hour_counts.columns\n",
        "\n",
        "# Plotting the value count by hour in a barplot which will make it look like a histogram\n",
        "hour_counts.plot(kind=\"bar\", x=\"hour\", y=\"count\", legend=None, color=\"pink\", figsize=(10, 6))\n",
        "\n",
        "plt.title(\"Distribution of Group Chat Activity by Hour of Day\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.ylabel(\"Message Count\")\n",
        "# Add very light x gridlines in between the names\n",
        "plt.grid(axis=\"y\", linestyle='--', linewidth=1, color='lightgrey')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "Ny7esQHZOCwF",
        "outputId": "e01305ff-9685-4596-d661-24b0b687b4af"
      },
      "outputs": [],
      "source": [
        "# Who is the most active contributor at which time (only peole with more than 500 messages)\n",
        "# only_200\n",
        "from_counts = pd.DataFrame(df.value_counts(\"from\")).reset_index()\n",
        "try:\n",
        "  from_counts[\"count\"]\n",
        "except KeyError:\n",
        "  from_counts.rename(columns={0: \"count\"}, inplace=True)\n",
        "from_counts\n",
        "names_200 = from_counts[from_counts[\"count\"] > 500][\"from\"].to_list() # not 500 but I was too lazy to refactor the variable names after this\n",
        "\n",
        "subset_cols = [\"from\", \"date\"]\n",
        "subset_df = df[subset_cols]\n",
        "subset_df['hour'] = subset_df['date'].dt.hour\n",
        "subset_200_df = subset_df[subset_df[\"from\"].isin(names_200)]\n",
        "subset_200_df[\"from\"] = subset_200_df[\"from\"].cat.remove_unused_categories() # this is important because otherwise filtered out people still get a spot in the legend\n",
        "\n",
        "\n",
        "only_name_hour_df = subset_200_df.drop(columns=\"date\")\n",
        "only_name_hour_df = pd.DataFrame(only_name_hour_df.value_counts()).reset_index()\n",
        "try:\n",
        "  only_name_hour_df[\"count\"]\n",
        "except KeyError:\n",
        "  only_name_hour_df.rename(columns={0: \"count\"}, inplace=True)\n",
        "\n",
        "# Calculate the total counts per person\n",
        "total_counts = only_name_hour_df.groupby('from', observed=True)['count'].sum()\n",
        "# Convert counts to percentages\n",
        "only_name_hour_df['percentage'] = round(only_name_hour_df['count'] / only_name_hour_df['from'].map(total_counts),3)\n",
        "\n",
        "\n",
        "# Sort the DataFrame by 'from' and 'hour'\n",
        "only_name_hour_df = only_name_hour_df.sort_values(by=['from', 'hour'])\n",
        "\n",
        "# Set up the plot\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Define a color palette\n",
        "color_palette = sns.color_palette(\"viridis\", n_colors=len(only_name_hour_df['from'].unique()))\n",
        "\n",
        "# Plot a grouped bar plot for each person\n",
        "sns.barplot(x='hour', y='percentage', hue='from', data=only_name_hour_df, palette=color_palette, ax=ax)\n",
        "\n",
        "# Add a smooth line (kernel density estimate) over the grouped bar plot\n",
        "for i, (name, group) in enumerate(only_name_hour_df.groupby('from', observed=True)):\n",
        "    sns.kdeplot(group['hour'], fill=True, alpha=0.02, linewidth=0.5, color=color_palette[i], ax=ax)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Hour of Day')\n",
        "ax.set_ylabel('Percentage of Person\\'s Messages')\n",
        "ax.set_title('Group Chat Activity per Person for Persons with more than 500 Messages')\n",
        "# Move the legend to the right\n",
        "ax.legend(title='Name', bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qxIAyijxOCwF",
        "outputId": "2bf90b9d-9b21-4fec-916a-11b07721fbc0"
      },
      "outputs": [],
      "source": [
        "# now as a heatmap\n",
        "\n",
        "# Convert 'date' to datetime format\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Create a new column for the hour of the day\n",
        "df['hour'] = df['date'].dt.hour\n",
        "\n",
        "# Filter data to include only people with at least 100 name occurrences\n",
        "name_counts = df['from'].value_counts()\n",
        "valid_names = name_counts[name_counts >= 100].index\n",
        "\n",
        "# Filter the DataFrame to include only rows with valid names\n",
        "df_filtered = df[df['from'].isin(valid_names)]\n",
        "df_filtered[\"from\"]= df_filtered[\"from\"].cat.remove_unused_categories()\n",
        "\n",
        "\n",
        "# Pivot the filtered DataFrame to have 'from' on one axis, 'hour' on the other, and values as percentages\n",
        "heatmap_data = (df_filtered.pivot_table(index='from', columns='hour', aggfunc='size', fill_value=0) /\n",
        "                df_filtered.groupby('from').size().values[:, None]) * 100\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "\n",
        "# Create a heatmap using seaborn with the 'coolwarm' color palette\n",
        "sns.heatmap(heatmap_data, cmap='rocket', annot=True, fmt='.1f', linewidths=.5, cbar_kws={'label': 'Percentage'}, ax=ax)\n",
        "\n",
        "# Set axis labels and title\n",
        "ax.set_xlabel('Hour of the Day')\n",
        "ax.set_ylabel('Name')\n",
        "ax.set_title('Heatmap of Activity Percentage by Hour of the Day and by Person (Minimum 100 Messages)')\n",
        "\n",
        "# Set y-axis ticks to match the number of valid names\n",
        "ax.set_yticks(range(len(valid_names)))\n",
        "# Set y-axis tick labels to valid names\n",
        "ax.set_yticklabels(valid_names)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g1yDJs_OCwF"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl9eWFp2OCwF",
        "outputId": "a2de8dbe-6e85-4ca0-ee4a-b22ad14d8f8d"
      },
      "outputs": [],
      "source": [
        "from germansentiment import SentimentModel\n",
        "from numpy import NaN\n",
        "import math\n",
        "\n",
        "model = SentimentModel()\n",
        "\n",
        "text = [\"so ein Idiot\", \"ja\", \"Wünsche euch einen herrlichen tag\", \"dies ist neutral\"]\n",
        "\n",
        "predictions = model.predict_sentiment(texts=text, output_probabilities=True)\n",
        "\n",
        "\n",
        "positive_scores = []\n",
        "negative_scores = []\n",
        "neutral_scores = []\n",
        "\n",
        "for i in predictions[1]:\n",
        "    positive_scores.append(i[0][1])\n",
        "    negative_scores.append(i[1][1])\n",
        "    neutral_scores.append(i[2][1])\n",
        "\n",
        "positive_scores = pd.DataFrame(positive_scores)\n",
        "negative_scores = pd.DataFrame(negative_scores)\n",
        "neutral_scores = pd.DataFrame(neutral_scores)\n",
        "print(positive_scores)\n",
        "# print(negative_scores)\n",
        "# print(neutral_scores)\n",
        "test_list = ['negaaaative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutraaaaal']\n",
        "test_list.extend(predictions[0])\n",
        "test_list_df = pd.DataFrame(test_list)\n",
        "print(test_list_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bYtjUrfK9ytJ",
        "outputId": "5726b217-e082-408e-85c5-398a269a15a9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript\n",
        "\n",
        "from germansentiment import SentimentModel\n",
        "from numpy import NaN\n",
        "import math\n",
        "\n",
        "model = SentimentModel()\n",
        "\n",
        "# Increase the data rate limit to 1e9 bytes/sec\n",
        "Javascript(\"Jupyter.notebook.iopub_data_rate_limit = 1e9;\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvRYKzzyQvm8"
      },
      "source": [
        "Let us run some example texts to see if the model is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcX-q2Z8QVER"
      },
      "outputs": [],
      "source": [
        "# test out the model\n",
        "\n",
        "text = [\"so ein Idiot\", \"ja\", \"Wünsche euch einen herrlichen tag\", \"dies ist neutral\"]\n",
        "\n",
        "predictions = model.predict_sentiment(texts=text, output_probabilities=True)\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj6Py6ZtQ5Zr"
      },
      "source": [
        "To predict all text sentiments at once, we need to batch the input. We do this process and storing the results in the function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeOY9arQ2_Pp"
      },
      "outputs": [],
      "source": [
        "# we take the predict function from the germansentiment model `predict_sentiment` that takes a list of texts and returns predictions\n",
        "# this function batches the input texts to batch_size and then predicts 50 at once\n",
        "\n",
        "def predict_sentiment_in_batches(texts, batch_size=50):\n",
        "\n",
        "    message_sentiment_rating = []\n",
        "    positive_scores = []\n",
        "    negative_scores = []\n",
        "    neutral_scores = []\n",
        "\n",
        "    num_batches = len(texts) // batch_size + (len(texts) % batch_size > 0)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        if i % 50 == 0:\n",
        "          print(f\"running batch {i}/{num_batches}\")\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = (i + 1) * batch_size\n",
        "\n",
        "        batch_texts = texts[start_idx:end_idx].astype(str).replace(\"\", \"dies ist neutral\")\n",
        "        batch_results = model.predict_sentiment(texts=batch_texts, output_probabilities=True)\n",
        "\n",
        "        # adding the batch results to the dictionaries\n",
        "        message_sentiment_rating.extend(batch_results[0]) # dont ask me why it is now extend and not append\n",
        "        for i in batch_results[1]:\n",
        "          positive_scores.append(i[0][1])\n",
        "          negative_scores.append(i[1][1])\n",
        "          neutral_scores.append(i[2][1])\n",
        "\n",
        "    # after all batches have run, convert dicts to dfs and merge them together\n",
        "    message_sentiment_rating = pd.DataFrame(message_sentiment_rating)\n",
        "    positive_scores = pd.DataFrame(positive_scores)\n",
        "    negative_scores = pd.DataFrame(negative_scores)\n",
        "    neutral_scores = pd.DataFrame(neutral_scores)\n",
        "\n",
        "    results_df = pd.DataFrame()\n",
        "    results_df[\"message_sentiment_rating\"] = message_sentiment_rating\n",
        "    results_df[\"positive_scores\"] = positive_scores\n",
        "    results_df[\"negative_scores\"] = negative_scores\n",
        "    results_df[\"neutral_scores\"] = neutral_scores\n",
        "\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYcwWCJrREax"
      },
      "source": [
        "now let us run the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "x4kRJVJI3ddw",
        "outputId": "9f7f0e80-0a61-45d9-ba8d-dc3984a7c5bd"
      },
      "outputs": [],
      "source": [
        "test_texte = df[\"text_cleaned\"]\n",
        "test_texte = test_texte.astype(str)\n",
        "test_texte = test_texte.replace(\"\", \"dies ist neutral\")\n",
        "\n",
        "# Process texts in batches\n",
        "batch_size = 50\n",
        "text_message_sentiment = predict_sentiment_in_batches(test_texte, batch_size=batch_size)\n",
        "\n",
        "# Display results\n",
        "text_message_sentiment[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "a0850hJ0OCwH",
        "outputId": "bea1deab-93de-4488-a605-3b9ce15874a5"
      },
      "outputs": [],
      "source": [
        "# merging the predictions with the original data\n",
        "df_with_sentiment = pd.concat((text_message_sentiment, df), axis=1)\n",
        "df_with_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "1r0HKBq-OCwH",
        "outputId": "1671c29e-947d-4c7e-8c09-9fac8206e25e"
      },
      "outputs": [],
      "source": [
        "# Group by 'name' and calculate the mean for each group\n",
        "columns_for_visual = [\"from\", \"positive_scores\", \"negative_scores\", \"neutral_scores\"]\n",
        "subset_df_for_visual = df_with_sentiment[columns_for_visual]\n",
        "grouped_df = subset_df_for_visual.groupby('from').mean()\n",
        "\n",
        "# Plot the grouped bar plot\n",
        "grouped_df.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Average Senttiment Scores for Each Name')\n",
        "plt.xlabel('Name')\n",
        "plt.ylabel('Average Score')\n",
        "plt.legend(title='Score Type')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "6nnsJYmsOCwH",
        "outputId": "d2f87077-9e00-49f9-d527-b6edd50fc31e"
      },
      "outputs": [],
      "source": [
        "# Filter data to include only people with at least 50 name occurrences\n",
        "name_counts = df_with_sentiment['from'].value_counts()\n",
        "valid_names = name_counts[name_counts >= 50].index\n",
        "\n",
        "# Filter the DataFrame to include only rows with valid names\n",
        "df_filtered = df_with_sentiment[df_with_sentiment['from'].isin(valid_names)]\n",
        "df_filtered[\"from\"]= df_filtered[\"from\"].cat.remove_unused_categories()\n",
        "\n",
        "\n",
        "\n",
        "columns_for_visual = [\"from\", \"message_sentiment_rating\"]\n",
        "subset_df_for_visual = df_filtered[columns_for_visual]\n",
        "\n",
        "# Group by 'name' and 'sentiment_rating' and get the relative counts\n",
        "grouped_df = subset_df_for_visual.groupby(['from', 'message_sentiment_rating']).size().unstack().fillna(0)\n",
        "grouped_df = grouped_df.div(grouped_df.sum(axis=1), axis=0) * 100  # Normalize to get percentages\n",
        "\n",
        "\n",
        "# Define custom colors for each sentiment rating\n",
        "colors = {'positive': 'green', 'neutral': 'grey', 'negative': 'red'}\n",
        "\n",
        "# Sort columns by the highest to lowest percentage count of \"negative\"\n",
        "grouped_df = grouped_df.reindex(grouped_df.sort_values(by='negative', ascending=False).index, axis=0)\n",
        "\n",
        "# Plot the 100% stacked bar plot with custom colors\n",
        "ax = grouped_df.plot(kind='bar', stacked=True, figsize=(14, 7), color=[colors[col] for col in grouped_df.columns])\n",
        "plt.title('Sentiment Ratings of Message Text for Each Name (min 50 messages)')\n",
        "plt.xlabel('Name')\n",
        "plt.ylabel('Percentage')\n",
        "plt.legend(title='Sentiment Rating', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(axis='y', zorder=0, color='black', linestyle='dotted', linewidth=0.3)\n",
        "\n",
        "\n",
        "# Add percent labels to each part of the bar plot\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    label_text = f'{height:.0f}%'\n",
        "    ax.text(x + width/2, y + height/2, label_text, ha='center', va='center', fontsize=8, color='white', rotation=90)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
